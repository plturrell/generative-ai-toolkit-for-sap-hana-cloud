# Together.ai Dedicated Endpoint Configuration

# API Authentication
apiKey: "8c2b1633069ad5a567299c19acb8db9cb2e0098d78d24556b1749f0149fcc729"

# Endpoint Configuration
endpoint:
  name: "sap-hana-ai-toolkit"
  description: "SAP HANA AI Toolkit with GPU Acceleration"
  
  # Hardware Configuration
  hardware:
    instanceType: "a100-40gb"  # Options: a100-40gb, a100-80gb, h100-80gb
    count: 1                   # Number of GPUs
    
  # Scaling Configuration
  scaling:
    minReplicas: 1
    maxReplicas: 2
    targetUtilization: 80      # Percentage
    
  # Model Configuration
  model:
    # Base model to use
    baseModel: "meta-llama/Llama-2-70b-chat-hf"
    
    # Quantization (optional)
    quantization:
      enabled: true
      method: "awq"           # Options: awq, gptq, none
      bits: 4                 # Options: 4, 8
    
    # Serving Configuration
    serving:
      maxTokens: 4096
      maxBatchSize: 32
      maxConcurrentRequests: 10
      timeout: 120            # Seconds
      
  # Network Configuration
  network:
    privateAccess: false      # Set to true for VPC peering
    allowedIPs: []            # Optional IP allowlist
    
  # Advanced Settings
  advanced:
    enableTensorRT: true
    enableFlashAttention: true
    enableKVCaching: true
    enableContinuousBatching: true
    schedulingStrategy: "fair" # Options: fair, fifo
    
# Monitoring and Logging
monitoring:
  logs:
    level: "INFO"
    retention: 7              # Days
  metrics:
    enabled: true
    prometheus: true
    
# Cost Management
billing:
  projectId: "sap-hana-toolkit"
  alertThreshold: 500         # USD