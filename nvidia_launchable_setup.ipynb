{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAP HANA AI Toolkit with NVIDIA Optimization\n",
    "\n",
    "This notebook provides setup instructions for running the SAP HANA AI Toolkit with NVIDIA GPU optimizations in VM Mode.\n",
    "\n",
    "## Why VM Mode is Required\n",
    "\n",
    "This project requires VM Mode for the following reasons:\n",
    "\n",
    "1. **Private Container Registry**: Uses NVIDIA NGC private registry requiring authentication\n",
    "2. **Direct GPU Access**: Requires direct GPU access for TensorRT optimization\n",
    "3. **External Authentication**: Connects to SAP HANA Cloud services requiring credentials\n",
    "4. **System Access**: Needs full system access for container orchestration\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- NVIDIA GPU (A100 or H100 recommended)\n",
    "- Docker with NVIDIA Container Toolkit\n",
    "- NGC account and API key\n",
    "- SAP HANA Cloud instance (optional for full functionality)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. NVIDIA NGC Authentication\n",
    "\n",
    "### 1.1 Create NGC Account\n",
    "\n",
    "If you don't already have an NGC account:\n",
    "\n",
    "1. Go to [NGC website](https://ngc.nvidia.com/) and sign up\n",
    "2. Verify your email address and complete registration\n",
    "\n",
    "### 1.2 Generate NGC API Key\n",
    "\n",
    "1. Log in to your NGC account\n",
    "2. Navigate to your account settings (click your name â†’ \"Setup\")\n",
    "3. Click \"Get API Key\"\n",
    "4. Generate a new API key and save it securely\n",
    "\n",
    "### 1.3 Log in to NGC Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Run this cell to log in to NGC\n",
    "!echo \"Please enter your NGC API key when prompted\"\n",
    "!docker login nvcr.io\n",
    "# Username: $oauthtoken\n",
    "# Password: <your NGC API key>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Set NGC API Key as Environment Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Set NGC API key (replace with your key)\n",
    "import os\n",
    "os.environ[\"NGC_API_KEY\"] = \"<your NGC API key>\"\n",
    "\n",
    "# Verify NGC authentication\n",
    "!curl -s -o /dev/null -w \"%{http_code}\" -H \"Authorization: ${NGC_API_KEY}\" https://api.ngc.nvidia.com/v2/org/nvidia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Verify GPU Environment\n",
    "\n",
    "Verify that GPUs are available and properly configured:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Check NVIDIA driver and GPU availability\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Verify NVIDIA Container Toolkit is installed and working\n",
    "!docker run --rm --gpus all nvcr.io/nvidia/cuda:12.2.0-base-ubuntu22.04 nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Pull NGC Container\n",
    "\n",
    "Pull the pre-optimized container from NGC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Pull the SAP HANA AI Toolkit container from NGC\n",
    "!docker pull nvcr.io/ea-sap/hana-ai-toolkit:latest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. SAP HANA Cloud Connection Setup (Optional)\n",
    "\n",
    "For connecting to SAP HANA Cloud, you'll need to provide connection credentials. These can be set as environment variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Set SAP HANA connection environment variables\n",
    "import os\n",
    "\n",
    "# Option 1: Direct credentials\n",
    "os.environ[\"HANA_HOST\"] = \"<your HANA host>\"\n",
    "os.environ[\"HANA_PORT\"] = \"443\"  # Default port\n",
    "os.environ[\"HANA_USER\"] = \"<your HANA username>\"\n",
    "os.environ[\"HANA_PASSWORD\"] = \"<your HANA password>\"\n",
    "\n",
    "# Option 2: Using HANA user key (if available)\n",
    "# os.environ[\"HANA_USERKEY\"] = \"<your HANA user key>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Configure Environment Variables\n",
    "\n",
    "Create a configuration file with environment variables for container deployment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create .env file for container configuration\n",
    "%%writefile .env\n",
    "# API Configuration\n",
    "API_HOST=0.0.0.0\n",
    "API_PORT=8000\n",
    "LOG_LEVEL=INFO\n",
    "LOG_FORMAT=json\n",
    "AUTH_REQUIRED=true\n",
    "API_KEYS=dev-key-only-for-testing  # Replace with secure key in production\n",
    "\n",
    "# NVIDIA GPU Configuration\n",
    "ENABLE_GPU_ACCELERATION=true\n",
    "NVIDIA_VISIBLE_DEVICES=all\n",
    "CUDA_MEMORY_FRACTION=0.8\n",
    "MULTI_GPU_STRATEGY=auto\n",
    "\n",
    "# TensorRT Optimization\n",
    "ENABLE_TENSORRT=true\n",
    "TENSORRT_PRECISION=fp16\n",
    "TENSORRT_MAX_BATCH_SIZE=32\n",
    "TENSORRT_WORKSPACE_SIZE_MB=1024\n",
    "TENSORRT_CACHE_DIR=/tmp/tensorrt_engines\n",
    "TENSORRT_BUILDER_OPTIMIZATION_LEVEL=3\n",
    "\n",
    "# Hopper Optimizations (if using H100 GPU)\n",
    "HOPPER_ENABLE_FLASH_ATTENTION=true\n",
    "HOPPER_ENABLE_FP8=true\n",
    "HOPPER_ENABLE_TRANSFORMER_ENGINE=true\n",
    "HOPPER_ENABLE_FSDP=true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Run the Container with GPU Acceleration\n",
    "\n",
    "Launch the container with GPU support and all required configurations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Run the container with GPU support\n",
    "!docker run -d \\\n",
    "  --name hana-ai-toolkit \\\n",
    "  --gpus all \\\n",
    "  -p 8000:8000 \\\n",
    "  -p 9090:9090 \\\n",
    "  --ipc=host \\\n",
    "  --ulimit memlock=-1 \\\n",
    "  --ulimit stack=67108864 \\\n",
    "  --env-file .env \\\n",
    "  nvcr.io/ea-sap/hana-ai-toolkit:latest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Verify Deployment\n",
    "\n",
    "Check if the API is running and GPU acceleration is enabled:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Check container logs\n",
    "!docker logs hana-ai-toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Check if API is running\n",
    "!curl -s http://localhost:8000/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Check metrics for GPU usage\n",
    "!curl -s http://localhost:9090/metrics | grep -i gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Run TensorRT Optimization Benchmark\n",
    "\n",
    "Test the TensorRT optimization with a simple benchmark:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Install Python requests if not already installed\n",
    "!pip install -q requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "\n",
    "# API endpoint\n",
    "url = \"http://localhost:8000/api/v1/llm\"\n",
    "\n",
    "# API key from environment variable\n",
    "headers = {\n",
    "    \"Authorization\": \"Bearer dev-key-only-for-testing\",  # Replace with your API key\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "# Request payload\n",
    "payload = {\n",
    "    \"model\": \"sap-ai-core-llama3\",\n",
    "    \"prompt\": \"Explain the benefits of GPU acceleration for deep learning inference.\",\n",
    "    \"max_tokens\": 200\n",
    "}\n",
    "\n",
    "# Benchmark function\n",
    "def run_benchmark(num_iterations=5):\n",
    "    total_time = 0\n",
    "    results = []\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        start_time = time.time()\n",
    "        response = requests.post(url, headers=headers, json=payload)\n",
    "        end_time = time.time()\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            response_data = response.json()\n",
    "            latency = end_time - start_time\n",
    "            total_time += latency\n",
    "            results.append({\n",
    "                \"iteration\": i + 1,\n",
    "                \"latency\": latency,\n",
    "                \"status\": \"success\"\n",
    "            })\n",
    "            print(f\"Iteration {i+1}: {latency:.3f} seconds\")\n",
    "        else:\n",
    "            print(f\"Iteration {i+1}: Failed with status code {response.status_code}\")\n",
    "            print(response.text)\n",
    "            results.append({\n",
    "                \"iteration\": i + 1,\n",
    "                \"status\": \"failed\",\n",
    "                \"error\": response.text\n",
    "            })\n",
    "    \n",
    "    if total_time > 0:\n",
    "        avg_latency = total_time / num_iterations\n",
    "        print(f\"\\nAverage latency: {avg_latency:.3f} seconds\")\n",
    "        print(f\"Throughput: {num_iterations / total_time:.2f} requests/second\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run the benchmark\n",
    "benchmark_results = run_benchmark()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Compare TensorRT vs. Standard Performance\n",
    "\n",
    "Let's compare performance with and without TensorRT optimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Stop the current container\n",
    "!docker stop hana-ai-toolkit\n",
    "!docker rm hana-ai-toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Modify .env file to disable TensorRT\n",
    "%%writefile .env\n",
    "# API Configuration\n",
    "API_HOST=0.0.0.0\n",
    "API_PORT=8000\n",
    "LOG_LEVEL=INFO\n",
    "LOG_FORMAT=json\n",
    "AUTH_REQUIRED=true\n",
    "API_KEYS=dev-key-only-for-testing\n",
    "\n",
    "# NVIDIA GPU Configuration\n",
    "ENABLE_GPU_ACCELERATION=true\n",
    "NVIDIA_VISIBLE_DEVICES=all\n",
    "CUDA_MEMORY_FRACTION=0.8\n",
    "MULTI_GPU_STRATEGY=auto\n",
    "\n",
    "# Disable TensorRT Optimization\n",
    "ENABLE_TENSORRT=false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Run the container without TensorRT\n",
    "!docker run -d \\\n",
    "  --name hana-ai-toolkit \\\n",
    "  --gpus all \\\n",
    "  -p 8000:8000 \\\n",
    "  -p 9090:9090 \\\n",
    "  --env-file .env \\\n",
    "  nvcr.io/ea-sap/hana-ai-toolkit:latest\n",
    "\n",
    "# Wait for container to start\n",
    "import time\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Run benchmark without TensorRT\n",
    "print(\"Running benchmark without TensorRT optimization:\")\n",
    "benchmark_results_no_tensorrt = run_benchmark()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Stop and remove container\n",
    "!docker stop hana-ai-toolkit\n",
    "!docker rm hana-ai-toolkit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrated how to:\n",
    "\n",
    "1. Authenticate with NVIDIA NGC\n",
    "2. Verify GPU environment and tools\n",
    "3. Pull and run the SAP HANA AI Toolkit container with GPU acceleration\n",
    "4. Configure TensorRT optimization\n",
    "5. Benchmark performance with and without TensorRT\n",
    "\n",
    "The results show significant performance improvements with TensorRT optimization, especially for inference workloads. The NGC container provides a pre-optimized environment with all the necessary NVIDIA optimizations for maximum performance.\n",
    "\n",
    "### Additional Resources\n",
    "\n",
    "- [Full Authentication Guide](https://github.com/finsightsap/generative-ai-toolkit-for-sap-hana-cloud/blob/main/AUTHENTICATION.md)\n",
    "- [NGC Deployment Guide](https://github.com/finsightsap/generative-ai-toolkit-for-sap-hana-cloud/blob/main/NGC_DEPLOYMENT.md)\n",
    "- [TensorRT Optimization Documentation](https://github.com/finsightsap/generative-ai-toolkit-for-sap-hana-cloud/blob/main/TENSORRT_OPTIMIZATION.md)\n",
    "- [NVIDIA GPU Optimization Guide](https://github.com/finsightsap/generative-ai-toolkit-for-sap-hana-cloud/blob/main/NVIDIA.md)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}